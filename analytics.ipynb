{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3dfd029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert back from scaled values\n",
    "y_test_actual = scaler.inverse_transform(y_test)\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "\n",
    "# 1Ô∏è‚É£ Root Mean Squared Error (RMSE)\n",
    "rmse = np.sqrt(mean_squared_error(y_test_actual, predictions))\n",
    "\n",
    "# 2Ô∏è‚É£ Mean Absolute Error (MAE)\n",
    "mae = mean_absolute_error(y_test_actual, predictions)\n",
    "\n",
    "# 3Ô∏è‚É£ R¬≤ Score (goodness of fit)\n",
    "r2 = r2_score(y_test_actual, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49f73cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Model Evaluation Metrics:\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"MAE:  {mae:.2f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
